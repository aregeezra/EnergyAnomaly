{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aregeezra/EnergyAnomaly/blob/main/EnergyAnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJCqJAL_qMNO"
      },
      "source": [
        "# 0.0 Installing necessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4V5MEU5qaqf"
      },
      "source": [
        "# 0.0 IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndIwRwALocUx",
        "outputId": "0546a648-22ea-4ee9-f6c2-017f12403563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import holidays\n",
        "\n",
        "from IPython.core.display  import HTML\n",
        "from IPython.display       import Image\n",
        "from datetime              import *\n",
        "from tabulate              import tabulate\n",
        "from scipy.stats           import chi2_contingency\n",
        "\n",
        "from boruta                import BorutaPy\n",
        "from sklearn.ensemble      import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model  import LinearRegression, Lasso\n",
        "from sklearn.ensemble      import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "import missingno as msno\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings( 'ignore' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z936NjaTpYiI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cramer_v( x, y ):\n",
        "    cm = pd.crosstab( x, y ).values\n",
        "    n = cm.sum()\n",
        "    r, k = cm.shape\n",
        "    \n",
        "    chi2 = chi2_contingency( cm )[0]\n",
        "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
        "    \n",
        "    kcorr = k - (k-1)**2/(n-1)\n",
        "    rcorr = r - (r-1)**2/(n-1)\n",
        "\n",
        "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
        "\n",
        "def settings():\n",
        "    %matplotlib inline\n",
        "    %pylab inline\n",
        "    \n",
        "    plt.style.use( 'bmh' )\n",
        "    plt.rcParams['figure.figsize'] = [25, 12]\n",
        "    plt.rcParams['font.size'] = 24\n",
        "    \n",
        "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
        "    pd.options.display.max_columns = None\n",
        "    pd.options.display.max_rows = None\n",
        "    pd.set_option( 'display.expand_frame_repr', False )\n",
        "    \n",
        "    sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SO7mpuuMqvEX",
        "outputId": "d1ead1c1-44d1-40cd-9051-bb2d56fbedc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "settings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3p6I4Wuubgi"
      },
      "source": [
        "# 0.2 Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_-zO2DWqwxT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "fb5cad88-264e-4346-90fe-db75e81ff88c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bb9e1700ca4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train_features.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_features.csv'"
          ]
        }
      ],
      "source": [
        "train_features = pd.read_csv('./train_features.csv',on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjGcmv4sRwBJ"
      },
      "outputs": [],
      "source": [
        "train_features.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJfQPlVUe2T-"
      },
      "source": [
        "# 1.0 Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrMe-jWvgEwY"
      },
      "source": [
        "## 1.1 Data Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r3wWSWze8U_"
      },
      "outputs": [],
      "source": [
        "print(f'Number of rows:{train_features.shape[0]}')\n",
        "print(f'Number of columns:{train_features.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gxm2c8VgsVc"
      },
      "source": [
        "# 1.3 Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwCach1RgolF"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"Data Types\": train_features.dtypes})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tilkcc0sQms"
      },
      "source": [
        "# 1.4 Check NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAY89K3cwodt"
      },
      "outputs": [],
      "source": [
        "train_features.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKlBs339IQ8U"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(train_features.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce0ZdJjBjDxQ"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"Missing Values(%)\":\n",
        "              train_features.isna().sum()/len(train_features.index)*100})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NSeRf44sHLh"
      },
      "source": [
        "# 1.5 Fillout NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h8It5RnsGx6"
      },
      "outputs": [],
      "source": [
        "mean1 = train_features['meter_reading'].mean()\n",
        "\n",
        "train_features['meter_reading'].fillna(value=mean1, inplace =True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMh_4ygHuVSN"
      },
      "source": [
        "# 1.6 Change Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF-c5dRFvYF-"
      },
      "outputs": [],
      "source": [
        "train_features.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntOsFqo1uUfz"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_features['timestamp'] = pd.to_datetime(train_features['timestamp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuBoJNTgth31"
      },
      "source": [
        "# 1.6 Descriptive Statistical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKINw-QBt6zB"
      },
      "outputs": [],
      "source": [
        "train_features.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6uRNCH4tb4o"
      },
      "outputs": [],
      "source": [
        "num1 = train_features.select_dtypes(include = ['float64'])\n",
        "cat1 = train_features.select_dtypes(exclude = ['float64', 'int64', 'datetime64[ns]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kED9Tv95OALk"
      },
      "outputs": [],
      "source": [
        "num1.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czxO83tdOOJn"
      },
      "outputs": [],
      "source": [
        "\n",
        "cat1.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z81mNiWVOgIK"
      },
      "source": [
        "## 1.6.1 Numerical Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOF20RPlOVD9"
      },
      "outputs": [],
      "source": [
        "# Central Tendency - mean, median\n",
        "ct1 = pd.DataFrame( num1.apply( np.mean ) ).T\n",
        "ct2 = pd.DataFrame( num1.apply( np.median ) ).T\n",
        "\n",
        "# Dispersion - std, min, max, range, skew, kurtosis\n",
        "d1 = pd.DataFrame( num1.apply( np.std ) ).T\n",
        "d2 = pd.DataFrame( num1.apply( min ) ).T\n",
        "d3 = pd.DataFrame( num1.apply( max ) ).T\n",
        "d4 = pd.DataFrame( num1.apply( lambda x: x.max() - x.min() ) ).T\n",
        "d5 = pd.DataFrame( num1.apply( lambda x: x.skew() ) ).T\n",
        "d6 = pd.DataFrame( num1.apply( lambda x: x.kurtosis() ) ).T\n",
        "d7 = pd.DataFrame( num1.apply(lambda x: x.var())).T\n",
        "# concatenate\n",
        "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6, d7] ).T.reset_index()\n",
        "m.columns = ( ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis', 'Variance'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdEst8gLPzBZ"
      },
      "outputs": [],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMFLcFrU9WN4"
      },
      "source": [
        "## 1.6.2 Categorical Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzGycRv99dvL"
      },
      "outputs": [],
      "source": [
        "cat1.apply( lambda x: x.unique().shape[0] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVr40hTASWQF"
      },
      "outputs": [],
      "source": [
        "df1 = train_features.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQzTgV1Q9o6B"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot( x= 'anomaly', y='meter_reading' , data=df1 )\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot( x= 'primary_use', y='meter_reading' , data=df1 )\n",
        "plt.xticks(rotation=90)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sus2EH6HUAGa"
      },
      "source": [
        "# 2.0 FEATURE ENGINEERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wC4NE4nQ06L"
      },
      "outputs": [],
      "source": [
        "df2 = df1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9zQWR8HURXC"
      },
      "outputs": [],
      "source": [
        "df2['timestamp'].sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Do_JsEXsRe"
      },
      "outputs": [],
      "source": [
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eAgmcPdWPGO"
      },
      "outputs": [],
      "source": [
        "df2['date'] = df2['timestamp'].dt.date\n",
        "\n",
        "df2['hour_of_day'] = df2['timestamp'].dt.hour\n",
        "\n",
        "df2['day_of_week'] = df2['timestamp'].dt.weekday\n",
        "\n",
        "df2['month'] = df2['timestamp'].dt.month\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7t_ru57Whqq"
      },
      "outputs": [],
      "source": [
        "df2.sample(10).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kllw0bntLnoB"
      },
      "source": [
        "# 3.0 EXPLORATORY DATA ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mljRHC_rMHnF"
      },
      "outputs": [],
      "source": [
        "df3 = df2.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2MpzM6mMfXi"
      },
      "source": [
        "## 3.1 Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJcbs2coMoF8"
      },
      "source": [
        "### 3.1.1 Response Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZoldSc_Krgm"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df3['meter_reading'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udifqGzuM7bM"
      },
      "source": [
        "### 3.1.2 Numerical Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxWBgeZFMynd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(24,15))\n",
        "num1.hist(bins=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmImR6SWN3qI"
      },
      "source": [
        "### 3.1.3 Categorical Variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMnny3LCNHKY"
      },
      "outputs": [],
      "source": [
        "cat1.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y9PMKK3OW0v"
      },
      "outputs": [],
      "source": [
        "df3.primary_use.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv02Y6fJOMcW"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1,2,1)\n",
        "sns.countplot(df3['primary_use'])\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.kdeplot( df3[df3['primary_use']=='Education']['meter_reading'], label='Education')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Office']['meter_reading'], label='Office')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Parking']['meter_reading'], label='Parking')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Lodging/residential']['meter_reading'], label='Lodging')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Entertainment/public assembly']['meter_reading'], label='Entertainment')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Public services']['meter_reading'], label='Public Service')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Manufacturing/industrial']['meter_reading'], label='Manufacturing/industrial')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Services']['meter_reading'], label='Services')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Other']['meter_reading'], label='Other')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Healthcare']['meter_reading'], label='Healthcare')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Food sales and service']['meter_reading'], label='FoodSale')\n",
        "sns.kdeplot( df3[df3['primary_use']=='Religious worship']['meter_reading'], label='Religious worship')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WTlE9RRaYWR"
      },
      "source": [
        "## 3.2 Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rZueHEScQo3"
      },
      "source": [
        "#### Percentage of Building with Anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283bLKTxMdvu"
      },
      "outputs": [],
      "source": [
        "\n",
        "df3['building_id'] = df3['building_id'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBOXY_KN7fcE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "anomaly = df3[['building_id', 'anomaly']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfkQbrRP7-iq"
      },
      "outputs": [],
      "source": [
        "anomaly.columns = ['Buildings', \"Anomaly\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq8Sevj68HA2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_stacked_bars(dataframe, title_, size_=(18, 10), rot_=0, legend_=\"upper right\"):\n",
        "\n",
        "  \"\"\"\n",
        "  Plot stacked bars with annotations\n",
        "  \"\"\"\n",
        "  ax = dataframe.plot(kind=\"bar\",\n",
        "                    stacked=True,\n",
        "                    figsize=size_,\n",
        "                    rot=rot_,\n",
        "                    title=title_)\n",
        "  # Annotate bars\n",
        "  annotate_stacked_bars(ax, textsize=14)\n",
        "  # Rename legend\n",
        "  plt.legend([\"Normal\", \"Anomaly\"], loc=legend_)\n",
        "  # Labels\n",
        "  plt.ylabel(\"Building base (%)\")\n",
        "  plt.show()\n",
        "\n",
        "def annotate_stacked_bars(ax, pad=0.99, colour=\"white\", textsize=13):\n",
        "  \"\"\"\n",
        "  Add value annotations to the bars\n",
        "  \"\"\"\n",
        "  # Iterate over the plotted rectanges/bars\n",
        "  for p in ax.patches:\n",
        "    # Calculate annotation\n",
        "    value = str(round(p.get_height(),1))\n",
        "    # If value is 0 do not annotate\n",
        "    if value == '0.0':\n",
        "     continue\n",
        "    ax.annotate(value,\n",
        "                ((p.get_x()+ p.get_width()/2)*pad-0.05, (p.get_y()+p.get_height()/2)*pad),\n",
        "                color=colour,\n",
        "                size=textsize,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8qtPrgd-tWo"
      },
      "outputs": [],
      "source": [
        "anomaly_total = anomaly.groupby(anomaly['Anomaly']).count()\n",
        "anomaly_percentage = anomaly_total / anomaly_total.sum() * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riTsLLssAtuL"
      },
      "outputs": [],
      "source": [
        "plot_stacked_bars(anomaly_percentage.transpose(),\"Building status\", (5,5), legend_=\"lower right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HSwVV9RjcSI"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=df3, x=\"building_id\", y=\"meter_reading\", hue=\"anomaly\",palette=['b', 'r'])\n",
        "plt.xticks(rotation=90)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CsilxHscZH0"
      },
      "source": [
        "Perecentage of Building with Anomalies categorized by the primary use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGmHiJOsOZS3"
      },
      "outputs": [],
      "source": [
        "sector = df3[['building_id', 'primary_use', 'anomaly']]\n",
        "sector = sector.groupby([sector['primary_use'], sector['anomaly']])['building_id'].count().unstack(level=1).fillna(0)\n",
        "sector_anomaly= (sector.div(sector.sum(axis=1), axis=0) * 100).sort_values(by=[1], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UytxxP2sRn7P"
      },
      "outputs": [],
      "source": [
        "plot_stacked_bars(sector_anomaly, \"Sector Anomaly\", rot_=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDntgX4ITECt"
      },
      "outputs": [],
      "source": [
        "time = df3[['building_id', 'hour_of_day', 'anomaly']]\n",
        "time = time.groupby([time['hour_of_day'], time['anomaly']])['building_id'].count().unstack(level=1).fillna(0)\n",
        "time_anomaly= (time.div(time.sum(axis=1), axis=0) * 100).sort_values(by=[1], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUMkXCNxTq4J"
      },
      "outputs": [],
      "source": [
        "plot_stacked_bars(time_anomaly, \"Time Anomaly\", rot_=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBE8UIKneF9F"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=df3, x=\"hour_of_day\", y=\"meter_reading\", hue=\"anomaly\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOG3k6vMjzAP"
      },
      "outputs": [],
      "source": [
        "day_of_week= df3[['building_id', 'weekday', 'anomaly']]\n",
        "day_of_week = day_of_week.groupby([day_of_week['weekday'], day_of_week['anomaly']])['building_id'].count().unstack(level=1).fillna(0)\n",
        "day_anomaly= (day_of_week.div(day_of_week.sum(axis=1), axis=0) * 100).sort_values(by=[1], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGdUWFsXk8G9"
      },
      "outputs": [],
      "source": [
        "plot_stacked_bars(day_anomaly, \"Day_Anomaly\", rot_=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HMIVnlGlPOA"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=df3, x=\"weekday\", y=\"meter_reading\", hue=\"anomaly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKVUQhIui7Jd"
      },
      "outputs": [],
      "source": [
        "df3.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4VIqS-1gF7k"
      },
      "outputs": [],
      "source": [
        "floor= df3[['building_id', 'floor_count', 'anomaly']]\n",
        "floor = floor.groupby([floor['floor_count'], floor['anomaly']])['building_id'].count().unstack(level=1).fillna(0)\n",
        "floor_anomaly= (floor.div(floor.sum(axis=1), axis=0) * 100).sort_values(by=[1], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHv4BcN1jXxy"
      },
      "outputs": [],
      "source": [
        "plot_stacked_bars(floor_anomaly, \"Floor Count Anomaly\", rot_=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bUb1plEwPHL"
      },
      "outputs": [],
      "source": [
        "df3.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YblBpg5XueV0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,54))\n",
        "plt.subplot(6,1,1)\n",
        "sns.scatterplot(data=df3, x=\"air_temperature\", y=\"meter_reading\",\n",
        "                hue=\"anomaly\", cmap=plt.cm.jet)\n",
        "\n",
        "plt.subplot(6,1,2)\n",
        "sns.scatterplot(data=df3, x=\"cloud_coverage\", y=\"meter_reading\",\n",
        "                hue=\"anomaly\", cmap=plt.cm.jet)\n",
        "\n",
        "plt.subplot(6,1,3)\n",
        "sns.scatterplot(data=df3, x=\"dew_temperature\", y=\"meter_reading\",\n",
        "                hue=\"anomaly\", cmap=plt.cm.jet)\n",
        "\n",
        "plt.subplot(6,1,4)\n",
        "sns.scatterplot(data=df3, x=\"sea_level_pressure\", y=\"meter_reading\",\n",
        "                hue=\"anomaly\", cmap=plt.cm.jet)\n",
        "\n",
        "plt.subplot(6,1,5)\n",
        "sns.scatterplot(data=df3, x=\"wind_direction\", y=\"meter_reading\",\n",
        "                hue=\"anomaly\", cmap=plt.cm.jet)\n",
        "\n",
        "plt.subplot(6,1,6)\n",
        "sns.scatterplot(data=df3, x=\"wind_speed\", y=\"meter_reading\",\n",
        "                hue=\"anomaly\", cmap=plt.cm.jet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3ip1J02JX_"
      },
      "source": [
        "## 3.3 Multivariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20edOYorwelV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(35, 45))\n",
        "correlation = num1.corr( method='pearson' )\n",
        "sns.heatmap( correlation, annot=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLBDN8NoD4WN"
      },
      "source": [
        "## 3.3.1 Prinicipal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whsr7WbsIj-8"
      },
      "source": [
        "Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. The number of distinct principal components is equal to the smaller of the number of original variables or the number of observations minus one. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal the preceding components. The resulting vectors are an uncorrelated orthogonal basis set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPuOciyTw_up"
      },
      "outputs": [],
      "source": [
        "df4 = df3.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuZx7LN5EPjJ"
      },
      "outputs": [],
      "source": [
        "df4.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFESYnJPwrwD"
      },
      "outputs": [],
      "source": [
        "df4.drop(['timestamp', 'primary_use',], axis = 1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EnergyAnomalyDetection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyJ4gddYinaLi2BvAxtlqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}